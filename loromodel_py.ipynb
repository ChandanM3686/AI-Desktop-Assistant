{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPp7KW9Kn3GExLzHx59oxXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChandanM3686/AI-Desktop-Assistant/blob/main/loromodel_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrUMuG-wH3eh",
        "outputId": "7d575e3a-d35b-47cc-9dfc-65fe2cf727f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def preprocess_images(input_dir, output_dir, image_size=256):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    image_list = os.listdir(input_dir)\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    for image_name in image_list:\n",
        "        image_path = os.path.join(input_dir, image_name)\n",
        "        img = Image.open(image_path)\n",
        "        img = preprocess(img)\n",
        "\n",
        "        # Convert tensor back to PIL image for saving\n",
        "        img = transforms.ToPILImage()(img)\n",
        "\n",
        "        save_path = os.path.join(output_dir, image_name)\n",
        "        img.save(save_path)\n",
        "\n",
        "# Example usage:\n",
        "input_dir = \"/content/sample_data/images.zip\"\n",
        "output_dir = \"preprocessed_images\"\n",
        "preprocess_images(input_dir, output_dir)\n"
      ],
      "metadata": {
        "id": "gPG8MGBQJqbI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LoRAModel(nn.Module):\n",
        "    def __init__(self, input_channels=3, hidden_channels=64, num_layers=5, kernel_size=3):\n",
        "        super(LoRAModel, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Input layer\n",
        "        self.layers.append(nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "        # Hidden layers\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.layers.append(nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "        # Output layer\n",
        "        self.layers.append(nn.Conv2d(hidden_channels, input_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "EqVYtMtCKBtq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "batch_size = 16\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Other hyperparameters\n",
        "image_size = 256  # Assuming square images\n",
        "input_channels = 3  # RGB images\n",
        "hidden_channels = 64\n",
        "num_layers = 5\n",
        "kernel_size = 3\n"
      ],
      "metadata": {
        "id": "Rr4xLnqhKWLx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class LoRAModel(nn.Module):\n",
        "    def __init__(self, input_channels=3, hidden_channels=64, num_layers=5, kernel_size=3):\n",
        "        super(LoRAModel, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "\n",
        "        self.layers.append(nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.layers.append(nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "\n",
        "        self.layers.append(nn.Conv2d(hidden_channels, input_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_list = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_list[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "eval_dataset = CustomImageDataset(root_dir=\"preprocessed_images\", transform=transform)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "image_size = 256\n",
        "input_channels = 3\n",
        "hidden_channels = 64\n",
        "num_layers = 5\n",
        "kernel_size = 3\n",
        "\n",
        "\n",
        "def preprocess_images(input_dir, output_dir, image_size=256):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    image_list = os.listdir(input_dir)\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    for image_name in image_list:\n",
        "        image_path = os.path.join(input_dir, image_name)\n",
        "        img = Image.open(image_path)\n",
        "        img = preprocess(img)\n",
        "\n",
        "\n",
        "        img = transforms.ToPILImage()(img)\n",
        "\n",
        "        save_path = os.path.join(output_dir, image_name)\n",
        "        img.save(save_path)\n",
        "\n",
        "model = LoRAModel(input_channels=input_channels, hidden_channels=hidden_channels, num_layers=num_layers, kernel_size=kernel_size)\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "input_dir = \"/content/sample_data/images.zip\"\n",
        "output_dir = \"preprocessed_images\"\n",
        "preprocess_images(input_dir, output_dir, image_size=image_size)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = CustomImageDataset(root_dir=output_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "\n",
        "        images = batch.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, images)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"lora_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0twx-QWKdRw",
        "outputId": "862c6a08-ae21-445c-f0c4-383896f67ec2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.34017181396484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Loss: 0.2736615836620331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Loss: 0.1639479398727417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Loss: 0.038389988243579865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Loss: 0.2052871435880661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Loss: 0.051607705652713776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Loss: 0.013179002329707146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Loss: 0.04220938682556152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Loss: 0.06739335507154465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Loss: 0.07422950863838196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Loss: 0.06550800800323486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Loss: 0.04857758432626724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Loss: 0.03435756638646126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Loss: 0.03379259631037712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Loss: 0.03906488046050072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Loss: 0.03086036629974842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Loss: 0.015971457585692406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Loss: 0.009414376690983772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Loss: 0.010952791199088097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Loss: 0.014657577499747276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
        "from skimage.metrics import structural_similarity as SSIM\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_list = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_list[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "model = LoRAModel(input_channels=input_channels, hidden_channels=hidden_channels, num_layers=num_layers, kernel_size=kernel_size)\n",
        "model.load_state_dict(torch.load(\"lora_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    psnr_values = []\n",
        "    ssim_values = []\n",
        "    for images in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "        images = images.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        outputs = outputs.clamp(0, 1)\n",
        "        for i in range(len(images)):\n",
        "            original_img = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "            generated_img = outputs[i].permute(1, 2, 0).cpu().numpy()\n",
        "            psnr = PSNR(original_img, generated_img)\n",
        "            ssim = SSIM(original_img, generated_img, multichannel=True)\n",
        "            psnr_values.append(psnr)\n",
        "            ssim_values.append(ssim)\n",
        "    avg_psnr = sum(psnr_values) / len(psnr_values)\n",
        "    avg_ssim = sum(ssim_values) / len(ssim_values)\n",
        "    return avg_psnr, avg_ssim\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "eval_dataset = CustomImageDataset(root_dir=\"preprocessed_images\", transform=transform)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "avg_psnr, avg_ssim = evaluate_model(model, eval_dataloader, device)\n",
        "print(f\"Average PSNR: {avg_psnr}, Average SSIM: {avg_ssim}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-NdxVHOK2eB",
        "outputId": "5ce377f5-754a-4796-b578-24b9f5db61fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   0%|          | 0/11 [00:00<?, ?it/s]<ipython-input-13-a68b61005b5c>:48: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim = SSIM(original_img, generated_img, multichannel=True)\n",
            "Evaluating: 100%|██████████| 11/11 [00:00<00:00, 42.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR: 17.96419098630483, Average SSIM: 0.8217360594055869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
        "from skimage.metrics import structural_similarity as SSIM\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class LoRAModel(nn.Module):\n",
        "    def __init__(self, input_channels=3, hidden_channels=64, num_layers=5, kernel_size=3):\n",
        "        super(LoRAModel, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        self.layers.append(nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.layers.append(nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "        self.layers.append(nn.Conv2d(hidden_channels, input_channels, kernel_size, padding=kernel_size//2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_list = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_list[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "def preprocess_images(input_dir, output_dir, image_size=256):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    image_list = os.listdir(input_dir)\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    for image_name in image_list:\n",
        "        image_path = os.path.join(input_dir, image_name)\n",
        "        img = Image.open(image_path)\n",
        "        img = preprocess(img)\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        save_path = os.path.join(output_dir, image_name)\n",
        "        img.save(save_path)\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    psnr_values = []\n",
        "    ssim_values = []\n",
        "    for images in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "        images = images.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        outputs = outputs.clamp(0, 1)\n",
        "        for i in range(len(images)):\n",
        "            original_img = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "            generated_img = outputs[i].permute(1, 2, 0).cpu().numpy()\n",
        "            psnr = PSNR(original_img, generated_img)\n",
        "            ssim = SSIM(original_img, generated_img, multichannel=True)\n",
        "            psnr_values.append(psnr)\n",
        "            ssim_values.append(ssim)\n",
        "    avg_psnr = sum(psnr_values) / len(psnr_values)\n",
        "    avg_ssim = sum(ssim_values) / len(ssim_values)\n",
        "    return avg_psnr, avg_ssim\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "image_size = 256\n",
        "input_channels = 3\n",
        "hidden_channels = 64\n",
        "num_layers = 5\n",
        "kernel_size = 3\n",
        "\n",
        "input_dir = \"/content/sample_data/images.zip\"\n",
        "output_dir = \"preprocessed_images\"\n",
        "preprocess_images(input_dir, output_dir, image_size=image_size)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = CustomImageDataset(root_dir=output_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LoRAModel(input_channels=input_channels, hidden_channels=hidden_channels, num_layers=num_layers, kernel_size=kernel_size)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"lora_model.pth\")\n",
        "\n",
        "# Generate new images using the trained LoRA model\n",
        "generated_images_dir = \"generated_images\"\n",
        "if not os.path.exists(generated_images_dir):\n",
        "    os.makedirs(generated_images_dir)\n",
        "\n",
        "eval_dataset = CustomImageDataset(root_dir=output_dir, transform=transform)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "for idx, image in enumerate(eval_dataloader):\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_image = model(image)\n",
        "    generated_image = generated_image.clamp(0, 1)\n",
        "    save_image(generated_image, os.path.join(generated_images_dir, f\"generated_image_{idx}.png\"))\n",
        "\n",
        "eval_dataset_generated = CustomImageDataset(root_dir=generated_images_dir, transform=transform)\n",
        "eval_dataloader_generated = DataLoader(eval_dataset_generated, batch_size=1, shuffle=False)\n",
        "\n",
        "avg_psnr, avg_ssim = evaluate_model(model, eval_dataloader_generated, device)\n",
        "print(f\"Average PSNR: {avg_psnr}, Average SSIM: {avg_ssim}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UKaFUUALNlT",
        "outputId": "d253cbc8-b969-47e0-cd44-2a3335bbaf79"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.3021722435951233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Loss: 0.2520662546157837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Loss: 0.1516309231519699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Loss: 0.020968178287148476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Loss: 0.257697194814682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Loss: 0.045001138001680374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Loss: 0.01753227598965168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Loss: 0.05589108169078827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Loss: 0.08464184403419495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Loss: 0.09495893865823746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Loss: 0.08886990696191788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Loss: 0.0696968212723732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Loss: 0.04266590252518654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Loss: 0.018152665346860886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Loss: 0.013834401033818722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Loss: 0.035855792462825775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Loss: 0.045880354940891266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Loss: 0.030994625762104988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Loss: 0.013902856037020683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Loss: 0.009683880023658276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   0%|          | 0/11 [00:00<?, ?it/s]<ipython-input-14-fee23a33aac1>:87: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim = SSIM(original_img, generated_img, multichannel=True)\n",
            "Evaluating: 100%|██████████| 11/11 [00:00<00:00, 49.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR: 23.51083204282689, Average SSIM: 0.9595467014746233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWnWb7TaP3m2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}